{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "1f113dc1581a41bea3c7e65f5d420283",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6198,
    "execution_start": 1666018874179,
    "source_hash": "5b854b5b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import aesara\n",
    "import aesara.tensor as at\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "\n",
    "from aesara.tensor.random.op import RandomVariable\n",
    "from pymc.distributions.continuous import PositiveContinuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "17cef7c51f0542d5b4db335bde42be6c",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Disambiguation and naming conventions\n",
    "\n",
    "There is some confusion regarding the input of each function. WFPT itself is a positive distribution, but input data might be negative due to negative decisions. In order for this code to be clear about the values of the input, it is a good idea to define the names of variables and specify what values they can take.\n",
    "\n",
    "* `data`: RTs that can take (-inf, inf), without non-decision time removed.\n",
    "* `rt`: RTs that can take (0, inf), with non-decision time removed.\n",
    "* `tt`: RTs that with non-decision time removed (rt - t) and normalized\n",
    "\n",
    "* `w`: normalized version of v.\n",
    "\n",
    "## Lessons learned:\n",
    "\n",
    "* Partitioning data is the fastest way to compute the PDF, but it's not differentiable\n",
    "* Using at.where() is slightly faster than using boolean computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "ca005384d002492eb2f2a17f19bb7c68",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 152,
    "execution_start": 1666018880385,
    "source_hash": "4f221f3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decision_func() -> Callable:\n",
    "    \"\"\"Partitions the data according to the result of the decision function.\n",
    "\n",
    "    Args:\n",
    "        w: Normalized RTs with negative values for negative decisions\n",
    "        decision: The output of the decision function. A boolean 1D array with True\n",
    "            indicating the fast expansion should be used and \"False\" otherwise.\n",
    "\n",
    "    Returns: A tuple with data that should be used with the fast and slow expansions.\n",
    "\n",
    "    \"\"\"\n",
    "    internal_tt = None\n",
    "    internal_err = None\n",
    "    internal_result = None\n",
    "\n",
    "    def inner_func(tt: np.ndarray, err: float = 1e-7) -> np.ndarray:\n",
    "        \"\"\"For each element in `x`, return `True` if the large-time expansion is\n",
    "        more efficient than the small-time expansion.\n",
    "\n",
    "        Args:\n",
    "            tt: An 1D numpy array of normalized RTs. (0, inf).\n",
    "            err: Error bound\n",
    "\n",
    "        Returns: a 1D boolean array of which implementation should be used.\n",
    "\n",
    "        \"\"\"\n",
    "        nonlocal internal_tt\n",
    "        nonlocal internal_err\n",
    "        nonlocal internal_result\n",
    "\n",
    "        if np.all(tt == internal_tt) and err == internal_err:\n",
    "            return internal_result\n",
    "\n",
    "        internal_tt = tt\n",
    "        internal_err = err\n",
    "\n",
    "        # determine number of terms needed for small-t expansion\n",
    "        ks = 2 + at.sqrt(-2 * tt * at.log(2 * np.sqrt(2 * np.pi * tt) * err))\n",
    "        ks = at.max(at.stack([ks, at.sqrt(tt) + 1]), axis=0)\n",
    "        ks = at.switch(2 * at.sqrt(2 * np.pi * tt) * err < 1, ks, 2)\n",
    "\n",
    "        # determine number of terms needed for large-t expansion\n",
    "        kl = at.sqrt(-2 * at.log(np.pi * tt * err) / (np.pi**2 * tt))\n",
    "        kl = at.max(at.stack([kl, 1.0 / (np.pi * at.sqrt(tt))]), axis=0)\n",
    "        kl = at.switch(np.pi * tt * err < 1, kl, 1.0 / (np.pi * at.sqrt(tt)))\n",
    "\n",
    "        lambda_tt = ks < kl\n",
    "\n",
    "        internal_result = lambda_tt\n",
    "\n",
    "        return lambda_tt\n",
    "\n",
    "    return inner_func\n",
    "\n",
    "\n",
    "decision = decision_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "09399b32d782477bb9ed4c1759822ac9",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1666018880587,
    "source_hash": "f21d63d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ftt01w_fast(tt_fast: np.ndarray, w: float, k_terms: int):\n",
    "    \"\"\"Density function for lower-bound first-passage times with drift rate set to 0 and\n",
    "    upper bound set to 1, calculated using the fast-RT expansion.\n",
    "\n",
    "    Args:\n",
    "        tt_fast: RTs. (0, inf).\n",
    "        w: Normalized decision starting point. (0, 1).\n",
    "        k_terms: number of terms to use to approximate the PDF\n",
    "\n",
    "    Returns:\n",
    "        The approximated function f(0, 1, w)\n",
    "    \"\"\"\n",
    "\n",
    "    k = at.arange(-at.floor((k_terms - 1) / 2), at.ceil((k_terms - 1) / 2) + 1)\n",
    "    y = w + 2 * k.reshape((-1, 1))\n",
    "    r = -at.power(y, 2) / 2 / tt_fast\n",
    "    c = at.max(r, axis=0)\n",
    "    p = at.exp(c + at.log(at.sum(y * at.exp(r - c), axis=0)))\n",
    "    p = p / at.sqrt(2 * np.pi * at.power(tt_fast, 3))\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def ftt01w_slow(tt_slow: np.ndarray, w: float, k_terms: int) -> np.ndarray:\n",
    "    \"\"\"Density function for lower-bound first-passage times with drift rate set to 0 and\n",
    "    upper bound set to 1, calculated using the slow-RT expansion.\n",
    "\n",
    "    Args:\n",
    "        tt_slow: RTs. (0, inf).\n",
    "        w: Normalized decision starting point. (0, 1).\n",
    "        k_terms: number of terms to use to approximate the PDF\n",
    "\n",
    "    Returns:\n",
    "        The approximated function f(0, 1, w)\n",
    "    \"\"\"\n",
    "\n",
    "    k = at.arange(1, k_terms + 1).reshape((-1, 1))\n",
    "    y = k * at.sin(k * np.pi * w)\n",
    "    r = -at.power(k, 2) * at.power(np.pi, 2) * tt_slow / 2\n",
    "    p = at.sum(y * at.exp(r), axis=0) * np.pi\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def ftt01w(\n",
    "    rt: np.ndarray,\n",
    "    a: float,\n",
    "    w: float,\n",
    "    err: float = 1e-7,\n",
    "    k_terms: int = 10,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute the likelihood of the drift diffusion model f(t|v,a,z) using the method\n",
    "    and implementation of Navarro & Fuss, 2009.\n",
    "\n",
    "    Args:\n",
    "        data: RTs. (-inf, inf) except 0. Negative values correspond to the lower bound.\n",
    "        v: Mean drift rate. (-inf, inf).\n",
    "        a: Value of decision upper bound. (0, inf).\n",
    "        z: Normalized decision starting point. (0, 1).\n",
    "        err: Error bound.\n",
    "    \"\"\"\n",
    "    lambda_tt = decision(rt, err)\n",
    "    tt = rt / a**2\n",
    "\n",
    "    p_fast = ftt01w_fast(tt, w, k_terms)\n",
    "    p_slow = ftt01w_slow(tt, w, k_terms)\n",
    "\n",
    "    return at.switch(lambda_tt, p_fast, p_slow)\n",
    "    # return lambda_tt * p_fast + (1 - lambda_tt) * p_slow\n",
    "\n",
    "\n",
    "def log_pdf_sv(\n",
    "    data: np.ndarray,\n",
    "    v: float,\n",
    "    sv: float,\n",
    "    a: float,\n",
    "    z: float,\n",
    "    t: float,\n",
    "    err: float = 1e-7,\n",
    "    k_terms: int = 10,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute the log-likelihood of the drift diffusion model f(t|v,a,z) using the method\n",
    "    and implementation of Navarro & Fuss, 2009.\n",
    "\n",
    "    Args:\n",
    "        x: RTs. (-inf, inf) except 0. Negative values correspond to the lower bound.\n",
    "        v: Mean drift rate. (-inf, inf).\n",
    "        a: Value of decision upper bound. (0, inf).\n",
    "        z: Normalized decision starting point. (0, 1).\n",
    "        err: Error bound.\n",
    "    \"\"\"\n",
    "    # First, convert data to positive\n",
    "    flip = data > 0\n",
    "    v = flip * -v + (1 - flip) * v  # transform v if x is upper-bound response\n",
    "    z = flip * (1 - z) + (1 - flip) * z  # transform z if x is upper-bound response\n",
    "    rt = np.abs(data)  # absolute rts\n",
    "    rt = rt - t  # remove nondecision time\n",
    "\n",
    "    p = ftt01w(rt, a, z, err, k_terms)\n",
    "\n",
    "    p = at.sum(\n",
    "        at.log(p)\n",
    "        + ((a * z * sv) ** 2 - 2 * a * v * z - (v**2) * rt) / (2 * (sv**2) * rt + 2)\n",
    "        - at.log(sv**2 * rt + 1) / 2\n",
    "        - 2 * at.log(a)\n",
    "    )\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "c95b6ec913354c4986f41b7d73767f06",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 42,
    "execution_start": 1666018880588,
    "source_hash": "a5434e10",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cavanaugh_data = pd.read_csv(\"cavanagh_theta_nn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "3ecd00b73e3547aa92379a56395dea9f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 699,
    "execution_start": 1666018880630,
    "source_hash": "1941bb0e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 258 ms, sys: 40.8 ms, total: 299 ms\n",
      "Wall time: 298 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(-37978.16611222)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "v = 1\n",
    "sv = 0\n",
    "a = 0.8\n",
    "z = 0.5\n",
    "t = 0.0\n",
    "\n",
    "log_pdf_sv(\n",
    "    cavanaugh_data.rt.values, v=v, sv=sv, a=a, z=z, t=0.0, err=1e-7, k_terms=15\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "7167159f78a7443aade9fb88f4ee10bb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4891,
    "execution_start": 1666018881382,
    "source_hash": "c40ed7c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 ms ± 1.98 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "log_pdf_sv(cavanaugh_data.rt.values, v=v, sv=sv, a=a, z=z, t=0.0, err=1e-7).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "46938fb6397e4c5582e6845cc9ff382a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 3,
    "execution_start": 1665756955202,
    "source_hash": "15a8cb5d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WFPTRandomVariable(RandomVariable):\n",
    "    \"\"\"WFPT random variable\"\"\"\n",
    "\n",
    "    name: str = \"WFPT_RV\"\n",
    "    ndim_supp: int = 0\n",
    "    ndims_params: List[int] = [0] * 10\n",
    "    dtype: str = \"floatX\"\n",
    "    _print_name: Tuple[str, str] = (\"WFPT\", \"WFPT\")\n",
    "\n",
    "    @classmethod\n",
    "    def rng_fn(\n",
    "        cls, rng: np.random.RandomState, v, sv, a, z, sz, t, st, q, l, r, size\n",
    "    ) -> np.ndarray:\n",
    "        return NotImplementedError(\"Not Implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "7ec70151edb84cc2aa12697b1694456d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 4,
    "execution_start": 1665756955209,
    "source_hash": "1c5324f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WFPT(PositiveContinuous):\n",
    "    \"\"\"Wiener first-passage time (WFPT) log-likelihood.\"\"\"\n",
    "\n",
    "    rv_op = WFPTRandomVariable()\n",
    "\n",
    "    @classmethod\n",
    "    def dist(cls, v, sv, a, z, t, **kwargs):\n",
    "        v = at.as_tensor_variable(pm.floatX(v))\n",
    "        sv = at.as_tensor_variable(pm.floatX(sv))\n",
    "        a = at.as_tensor_variable(pm.floatX(a))\n",
    "        z = at.as_tensor_variable(pm.floatX(z))\n",
    "        t = at.as_tensor_variable(pm.floatX(t))\n",
    "        return super().dist([v, sv, a, z, t], **kwargs)\n",
    "\n",
    "    def logp(data, v, sv, a, z, t, err=1e-7, k_terms=10, **kwargs):\n",
    "\n",
    "        return log_pdf_sv(data, v, sv, a, z, t, err, k_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "0f1cf55473ad4264b33a0de02c30f7e5",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1665756955275,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [v]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:00&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 9 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference data with groups:\n",
      "\t> posterior\n",
      "\t> log_likelihood\n",
      "\t> sample_stats\n",
      "\t> observed_data\n"
     ]
    }
   ],
   "source": [
    "with pm.Model():\n",
    "\n",
    "    sv = 0\n",
    "    a = 0.8\n",
    "    z = 0.5\n",
    "    t = 0.0\n",
    "\n",
    "    v = pm.Normal(name=\"v\")\n",
    "    WFPT(name=\"x\", v=v, sv=sv, a=a, z=z, t=t, observed=cavanaugh_data.rt.values)\n",
    "    results = pm.sample(1000, return_inferencedata=True)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=309a84a8-4378-4e4a-ad40-54daa1f48cb7' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.log_likelihood.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9499b13cee0d4e4dbe1b79df88c30ec8",
  "deepnote_persisted_session": {
   "createdAt": "2022-10-14T16:01:46.840Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "863c6a44cfff4c29a6496ebe197384a1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4993,
    "execution_start": 1666018851114,
    "source_hash": "5b854b5b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import aesara.tensor as at\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pandas as pd\n",
    "\n",
    "from aesara.tensor.random.op import RandomVariable\n",
    "from pymc.distributions.continuous import PositiveContinuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "80f3fe62a97044b195d583cfcd20b436",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Disambiguation and naming conventions\n",
    "\n",
    "There is some confusion regarding the input of each function. WFPT itself is a positive distribution, but input data might be negative due to negative decisions. In order for this code to be clear about the values of the input, it is a good idea to define the names of variables and specify what values they can take.\n",
    "\n",
    "* `data`: RTs that can take (-inf, inf), without non-decision time removed.\n",
    "* `rt`: RTs that can take (0, inf), with non-decision time removed.\n",
    "* `tt`: RTs that with non-decision time removed (rt - t) and normalized\n",
    "\n",
    "* `w`: normalized version of v.\n",
    "\n",
    "## Lessons learned:\n",
    "\n",
    "* Partitioning data is the fastest way to compute the PDF, but it's not differentiable\n",
    "* Using at.where() is slightly faster than using boolean computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "1f36514bc99542348d88079d8c020e97",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 43,
    "execution_start": 1666018856267,
    "source_hash": "4f221f3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decision_func() -> Callable:\n",
    "    \"\"\"Partitions the data according to the result of the decision function.\n",
    "\n",
    "    Args:\n",
    "        w: Normalized RTs with negative values for negative decisions\n",
    "        decision: The output of the decision function. A boolean 1D array with True\n",
    "            indicating the fast expansion should be used and \"False\" otherwise.\n",
    "\n",
    "    Returns: A tuple with data that should be used with the fast and slow expansions.\n",
    "\n",
    "    \"\"\"\n",
    "    internal_tt = None\n",
    "    internal_err = None\n",
    "    internal_result = None\n",
    "\n",
    "    def inner_func(tt: np.ndarray, err: float = 1e-7) -> np.ndarray:\n",
    "        \"\"\"For each element in `x`, return `True` if the large-time expansion is\n",
    "        more efficient than the small-time expansion.\n",
    "\n",
    "        Args:\n",
    "            tt: An 1D numpy array of normalized RTs. (0, inf).\n",
    "            err: Error bound\n",
    "\n",
    "        Returns: a 1D boolean array of which implementation should be used.\n",
    "\n",
    "        \"\"\"\n",
    "        nonlocal internal_tt\n",
    "        nonlocal internal_err\n",
    "        nonlocal internal_result\n",
    "\n",
    "        if np.all(tt == internal_tt) and err == internal_err:\n",
    "            return internal_result\n",
    "\n",
    "        internal_tt = tt\n",
    "        internal_err = err\n",
    "\n",
    "        # determine number of terms needed for small-t expansion\n",
    "        ks = 2 + at.sqrt(-2 * tt * at.log(2 * np.sqrt(2 * np.pi * tt) * err))\n",
    "        ks = at.max(at.stack([ks, at.sqrt(tt) + 1]), axis=0)\n",
    "        ks = at.where(2 * at.sqrt(2 * np.pi * tt) * err < 1, ks, 2)\n",
    "\n",
    "        # determine number of terms needed for large-t expansion\n",
    "        kl = at.sqrt(-2 * at.log(np.pi * tt * err) / (np.pi**2 * tt))\n",
    "        kl = at.max(at.stack([kl, 1.0 / (np.pi * at.sqrt(tt))]), axis=0)\n",
    "        kl = at.where(np.pi * tt * err < 1, kl, 1.0 / (np.pi * at.sqrt(tt)))\n",
    "\n",
    "        lambda_tt = ks < kl\n",
    "\n",
    "        internal_result = lambda_tt\n",
    "\n",
    "        return lambda_tt\n",
    "\n",
    "    return inner_func\n",
    "\n",
    "\n",
    "decision = decision_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "592e9f74504645bfa2ff0c5ba3fac299",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 45,
    "execution_start": 1666018856354,
    "source_hash": "f248eaf3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ftt01w_fast(tt_fast: np.ndarray, w: float, k_terms: int):\n",
    "    \"\"\"Density function for lower-bound first-passage times with drift rate set to 0 and\n",
    "    upper bound set to 1, calculated using the fast-RT expansion.\n",
    "\n",
    "    Args:\n",
    "        tt_fast: RTs. (0, inf).\n",
    "        w: Normalized decision starting point. (0, 1).\n",
    "        k_terms: number of terms to use to approximate the PDF\n",
    "\n",
    "    Returns:\n",
    "        The approximated function f(0, 1, w)\n",
    "    \"\"\"\n",
    "\n",
    "    k = at.arange(k_terms) - at.floor((k_terms - 1) / 2.0)\n",
    "    y = w + 2 * k.reshape((-1, 1))\n",
    "    r = -at.power(y, 2) / 2 / tt_fast\n",
    "    c = at.max(r, axis=0)\n",
    "    p = at.exp(c + at.log(at.sum(y * at.exp(r - c), axis=0)))\n",
    "    p = p / at.sqrt(2 * np.pi * at.power(tt_fast, 3))\n",
    "\n",
    "    # k = (at.arange(k_terms) - at.floor((k_terms - 1) / 2)).reshape((-1, 1))\n",
    "    # p = (w + 2 * k) * at.exp(-((w + 2 * k) ** 2) / (2 * tt_fast))\n",
    "    # p = at.sum(p, axis=0) / at.sqrt(2 * np.pi * at.power(tt_fast, 3))\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def ftt01w_slow(tt_slow: np.ndarray, w: float, k_terms: int) -> np.ndarray:\n",
    "    \"\"\"Density function for lower-bound first-passage times with drift rate set to 0 and\n",
    "    upper bound set to 1, calculated using the slow-RT expansion.\n",
    "\n",
    "    Args:\n",
    "        tt_slow: RTs. (0, inf).\n",
    "        w: Normalized decision starting point. (0, 1).\n",
    "        k_terms: number of terms to use to approximate the PDF\n",
    "\n",
    "    Returns:\n",
    "        The approximated function f(0, 1, w)\n",
    "    \"\"\"\n",
    "\n",
    "    k = at.arange(1, k_terms + 1).reshape((-1, 1))\n",
    "    y = k * at.sin(k * np.pi * w)\n",
    "    r = -at.power(k, 2) * at.power(np.pi, 2) * tt_slow / 2\n",
    "    p = at.sum(y * at.exp(r), axis=0) * np.pi\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "def ftt01w(\n",
    "    rt: np.ndarray,\n",
    "    a: float,\n",
    "    w: float,\n",
    "    err: float = 1e-7,\n",
    "    k_terms: int = 10,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute the likelihood of the drift diffusion model f(t|v,a,z) using the method\n",
    "    and implementation of Navarro & Fuss, 2009.\n",
    "\n",
    "    Args:\n",
    "        data: RTs. (-inf, inf) except 0. Negative values correspond to the lower bound.\n",
    "        v: Mean drift rate. (-inf, inf).\n",
    "        a: Value of decision upper bound. (0, inf).\n",
    "        z: Normalized decision starting point. (0, 1).\n",
    "        err: Error bound.\n",
    "    \"\"\"\n",
    "    lambda_tt = decision(rt, err)\n",
    "    tt = rt / a**2\n",
    "\n",
    "    if at.all(lambda_tt).eval():\n",
    "        p_fast = ftt01w_fast(tt, w, k_terms)\n",
    "        return p_fast, rt, None, None\n",
    "\n",
    "    if at.all(~lambda_tt).eval():\n",
    "        p_slow = ftt01w_slow(tt, w, k_terms)\n",
    "        return None, None, p_slow, rt\n",
    "\n",
    "    tt_fast = tt[lambda_tt]\n",
    "    tt_slow = tt[~lambda_tt]\n",
    "\n",
    "    p_fast = ftt01w_fast(tt_fast, w, k_terms)\n",
    "    p_slow = ftt01w_slow(tt_slow, w, k_terms)\n",
    "\n",
    "    return p_fast, rt[lambda_tt], p_slow, rt[~lambda_tt]\n",
    "    # return lambda_tt * p_fast + (1 - lambda_tt) * p_slow\n",
    "\n",
    "\n",
    "def log_pdf_sv(\n",
    "    data: np.ndarray,\n",
    "    v: float,\n",
    "    sv: float,\n",
    "    a: float,\n",
    "    z: float,\n",
    "    t: float,\n",
    "    err: float = 1e-7,\n",
    "    k_terms: int = 10,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Compute the log-likelihood of the drift diffusion model f(t|v,a,z) using the method\n",
    "    and implementation of Navarro & Fuss, 2009.\n",
    "\n",
    "    Args:\n",
    "        x: RTs. (-inf, inf) except 0. Negative values correspond to the lower bound.\n",
    "        v: Mean drift rate. (-inf, inf).\n",
    "        a: Value of decision upper bound. (0, inf).\n",
    "        z: Normalized decision starting point. (0, 1).\n",
    "        err: Error bound.\n",
    "    \"\"\"\n",
    "    # First, convert data to positive\n",
    "    flip = data > 0\n",
    "    v = flip * -v + (1 - flip) * v  # transform v if x is upper-bound response\n",
    "    z = flip * (1 - z) + (1 - flip) * z  # transform z if x is upper-bound response\n",
    "    rt = np.abs(data)  # absolute rts\n",
    "    rt = rt - t  # remove nondecision time\n",
    "\n",
    "    w = z / a\n",
    "    p_fast, rt_fast, p_slow, rt_slow = ftt01w(rt, a, w, err, k_terms)\n",
    "\n",
    "    p = 0.0\n",
    "\n",
    "    if p_fast is not None:\n",
    "        p_fast = at.sum(\n",
    "            at.log(p_fast)\n",
    "            + ((a * z * sv) ** 2 - 2 * a * v * z - (v**2) * rt_fast)\n",
    "            / (2 * (sv**2) * rt_fast + 2)\n",
    "            - at.log(sv**2 * rt_fast + 1) / 2\n",
    "            - 2 * at.log(a)\n",
    "        )\n",
    "        print(p_fast.eval())\n",
    "        p += p_fast\n",
    "\n",
    "    if p_slow is not None:\n",
    "        p_slow = at.sum(\n",
    "            at.log(p_slow)\n",
    "            + ((a * z * sv) ** 2 - 2 * a * v * z - (v**2) * rt_slow)\n",
    "            / (2 * (sv**2) * rt_slow + 2)\n",
    "            - at.log(sv**2 * rt_slow + 1) / 2\n",
    "            - 2 * at.log(a)\n",
    "        )\n",
    "        p += p_slow\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "44c7ffbd216f492db7d1fbc03089d928",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 367,
    "execution_start": 1666018856399,
    "source_hash": "a5434e10",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cavanaugh_data = pd.read_csv(\"cavanagh_theta_nn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.21  1.63  1.03  ... 0.784 2.35  1.25 ]\n"
     ]
    }
   ],
   "source": [
    "print(cavanaugh_data.rt.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "4c0d28ed77f845f4aebc10f232b98ef2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 843,
    "execution_start": 1666018856797,
    "source_hash": "1941bb0e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 281 ms, sys: 34 ms, total: 315 ms\n",
      "Wall time: 315 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(-38293.91432182)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "v = 1\n",
    "sv = 0\n",
    "a = 0.8\n",
    "z = 0.5\n",
    "t = 0.0\n",
    "\n",
    "log_pdf_sv(\n",
    "    cavanaugh_data.rt.values, v=v, sv=sv, a=a, z=z, t=0.0, err=1e-7, k_terms=12\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-38293.91432182)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pdf_sv(\n",
    "    cavanaugh_data.rt.values, v=v, sv=sv, a=a, z=z, t=0.0, err=1e-7, k_terms=7\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "261310700ad448b0be1530fb8388beb4",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 20884,
    "execution_start": 1666018857186,
    "source_hash": "c40ed7c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 ms ± 371 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "log_pdf_sv(cavanaugh_data.rt.values, v=v, sv=sv, a=a, z=z, t=0.0, err=1e-7).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "ea4cded0b2354e318e448d356b13b30e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6,
    "execution_start": 1666018878072,
    "source_hash": "f1e783a0",
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4067800170.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    stop here\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b17c2f94a71f4742b2bdfeb531833a37",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 3,
    "execution_start": 1665756955202,
    "source_hash": "15a8cb5d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WFPTRandomVariable(RandomVariable):\n",
    "    \"\"\"WFPT random variable\"\"\"\n",
    "\n",
    "    name: str = \"WFPT_RV\"\n",
    "    ndim_supp: int = 0\n",
    "    ndims_params: List[int] = [0] * 9\n",
    "    dtype: str = \"floatX\"\n",
    "    _print_name: Tuple[str, str] = (\"WFPT\", \"WFPT\")\n",
    "\n",
    "    @classmethod\n",
    "    def rng_fn(\n",
    "        cls, rng: np.random.RandomState, v, sv, a, z, sz, t, st, q, l, r, size\n",
    "    ) -> np.ndarray:\n",
    "        return NotImplementedError(\"Not Implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4fab2eedc0d449c6b92ad82a499fbf4f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 4,
    "execution_start": 1665756955209,
    "source_hash": "1c5324f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WFPT(PositiveContinuous):\n",
    "    \"\"\"Wiener first-passage time (WFPT) log-likelihood.\"\"\"\n",
    "\n",
    "    rv_op = WFPTRandomVariable()\n",
    "\n",
    "    @classmethod\n",
    "    def dist(cls, v, sv, a, z, **kwargs):\n",
    "        v = at.as_tensor_variable(pm.floatX(v))\n",
    "        sv = at.as_tensor_variable(pm.floatX(sv))\n",
    "        a = at.as_tensor_variable(pm.floatX(a))\n",
    "        z = at.as_tensor_variable(pm.floatX(z))\n",
    "        return super().dist([v, sv, a, z, t], **kwargs)\n",
    "\n",
    "    def logp(self, data, v, sv, a, z, t):\n",
    "\n",
    "        # First, convert data to positive\n",
    "        flip = data > 0\n",
    "        v = flip * -v + (1 - flip) * v  # transform v if x is upper-bound response\n",
    "        z = flip * (1 - z) + (1 - flip) * z  # transform z if x is upper-bound response\n",
    "        rt = np.abs(x)  # absolute rts\n",
    "        tt = x - t  # remove nondecision time\n",
    "\n",
    "        return log_pdf_sv(tt, v, sv, a, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "49b8c5d485b54071a4a4696d62fe9e8b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 1,
    "execution_start": 1665756955275,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=309a84a8-4378-4e4a-ad40-54daa1f48cb7' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "01b17cf59e7d4151bbe39613a828a8c4",
  "deepnote_persisted_session": {
   "createdAt": "2022-10-14T16:01:46.840Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

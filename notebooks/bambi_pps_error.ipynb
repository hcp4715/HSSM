{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a826bd-8bda-4150-b160-640b5ac21607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import bambi as bmb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytensor\n",
    "\n",
    "import hssm\n",
    "import ssms.basic_simulators\n",
    "\n",
    "pytensor.config.floatX = \"float32\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c445c6-8fe2-4f82-820a-d0715c3aaf9e",
   "metadata": {},
   "source": [
    "### Using include paramater to use regression and update priors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affc0a8-6966-4988-af1e-943d56414e94",
   "metadata": {},
   "source": [
    "#### Case 1: Regression type formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77c09a1-978c-4c33-bfd5-9d5d96368c46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get some fake simulation data\n",
    "intercept = 0.3\n",
    "x = np.random.uniform(0.2, 0.5, size=1000)\n",
    "y = np.random.uniform(0.1, 0.4, size=1000)\n",
    "\n",
    "v = intercept + 0.8 * x + 0.3 * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791e2540-25e3-49b0-92fa-6a9ba8d92072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_values = np.column_stack(\n",
    "    [v, np.repeat([[1.5, 0.5, 0.5, 0.0]], axis=0, repeats=1000)]\n",
    ")\n",
    "true_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd7adf3-4854-40f4-9adb-8bed11ec5e77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>response</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.202986</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413635</td>\n",
       "      <td>0.202105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.773003</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361816</td>\n",
       "      <td>0.154223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.144021</td>\n",
       "      <td>1</td>\n",
       "      <td>0.216562</td>\n",
       "      <td>0.316722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.406610</td>\n",
       "      <td>1</td>\n",
       "      <td>0.442631</td>\n",
       "      <td>0.194695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.895009</td>\n",
       "      <td>1</td>\n",
       "      <td>0.297407</td>\n",
       "      <td>0.142648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1.422992</td>\n",
       "      <td>1</td>\n",
       "      <td>0.332995</td>\n",
       "      <td>0.332539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3.303979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.310310</td>\n",
       "      <td>0.212713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.640997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202920</td>\n",
       "      <td>0.353149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>1.836006</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.421434</td>\n",
       "      <td>0.244051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.915998</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.431373</td>\n",
       "      <td>0.237661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rt  response         x         y\n",
       "0    3.202986         1  0.413635  0.202105\n",
       "1    1.773003         1  0.361816  0.154223\n",
       "2    2.144021         1  0.216562  0.316722\n",
       "3    8.406610         1  0.442631  0.194695\n",
       "4    1.895009         1  0.297407  0.142648\n",
       "..        ...       ...       ...       ...\n",
       "995  1.422992         1  0.332995  0.332539\n",
       "996  3.303979         1  0.310310  0.212713\n",
       "997  1.640997         1  0.202920  0.353149\n",
       "998  1.836006        -1  0.421434  0.244051\n",
       "999  0.915998        -1  0.431373  0.237661\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_ddm_reg_v = ssms.basic_simulators.simulator(true_values, model=\"ddm\", n_samples=1)\n",
    "obs_ddm_reg_v\n",
    "\n",
    "dataset_reg_v = pd.DataFrame(\n",
    "    {\n",
    "        \"rt\": obs_ddm_reg_v[\"rts\"].flatten(),\n",
    "        \"response\": obs_ddm_reg_v[\"choices\"].flatten(),\n",
    "        \"x\": x,\n",
    "        \"y\": y,\n",
    "    }\n",
    ")\n",
    "\n",
    "dataset_reg_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410c315-0319-4259-92a8-453b2bc732d8",
   "metadata": {},
   "source": [
    "- v is parent\n",
    "- x is a feature from the dataset_reg_v\n",
    "- y is a feature from the dataset_reg_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caaf6041-2ae0-477c-a35e-2d504f62a508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loglik = hssm.wfpt.WFPT\n",
    "\n",
    "priors = {\n",
    "    \"c(rt, response)\": {\n",
    "        \"Intercept\": bmb.Prior(\"Uniform\", lower=0.0, upper=0.5),\n",
    "        \"x\": bmb.Prior(\"Uniform\", lower=0.0, upper=1.0),\n",
    "        \"y\": bmb.Prior(\"Uniform\", lower=0.0, upper=1.0),\n",
    "    },\n",
    "    \"a\": bmb.Prior(\"Uniform\", lower=0.3, upper=2.5),\n",
    "    \"z\": bmb.Prior(\"Uniform\", lower=0.1, upper=0.9),\n",
    "    \"t\": bmb.Prior(\"Uniform\", lower=0.0, upper=2.0),\n",
    "}\n",
    "\n",
    "links = {\"v\": \"identity\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02686d0f-508c-4bb1-bb38-5a82cda9eb95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likelihood = bmb.Likelihood(\n",
    "    \"WFPT_Loglik\", params=[\"v\", \"a\", \"z\", \"t\"], parent=\"v\", dist=loglik\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c0f10c-48c5-4941-baa9-890383107277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "family = bmb.Family(\"WFPT_Family\", likelihood=likelihood, link=links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568808e9-3cc1-48df-b52e-b513cae60f00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bambi_model = bmb.Model(\n",
    "    \"c(rt, response) ~ 1 + x + y\", data=dataset_reg_v, family=family, priors=priors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22eae8bc-b43a-465c-8e6c-b182473b573a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (2 chains in 1 job)\n",
      "NUTS: [c(rt, response)_z, c(rt, response)_t, c(rt, response)_a, Intercept, x, y]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1500' class='' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1500/1500 00:10&lt;00:00 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1500' class='' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1500/1500 00:09&lt;00:00 Sampling chain 1, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 2 chains for 1_000 tune and 500 draw iterations (2_000 + 1_000 draws total) took 20 seconds.\n",
      "We recommend running at least 4 chains for robust computation of convergence diagnostics\n"
     ]
    }
   ],
   "source": [
    "sample = bambi_model.fit(\n",
    "    cores=1,\n",
    "    chains=2,\n",
    "    draws=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3903334-bac5-4ddf-b766-bd36b714a04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make some new data points\n",
    "new_data = pd.DataFrame(\n",
    "    {\n",
    "        \"x\": np.random.uniform(0.2, 0.5, size=10),\n",
    "        \"y\": np.random.uniform(0.1, 0.4, size=10),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6848a59-262b-4ee1-822f-8ab30d25f5a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "coordinate chain has dimensions ('chain',), but these are not a subset of the DataArray dimensions ('dim_0', 'dim_1', 'dim_2', 'dim_3')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# posterior predictive sampling\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbambi_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/models.py:800\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, idata, kind, data, inplace, include_group_specific)\u001b[0m\n\u001b[1;32m    797\u001b[0m required_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m\"\u001b[39m: idata\u001b[38;5;241m.\u001b[39mposterior}\n\u001b[1;32m    798\u001b[0m optional_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data}\n\u001b[0;32m--> 800\u001b[0m pps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfamily\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_predictive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequired_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptional_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m pps \u001b[38;5;241m=\u001b[39m pps\u001b[38;5;241m.\u001b[39mto_dataset(name\u001b[38;5;241m=\u001b[39mresponse_aliased_name)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior_predictive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m idata:\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/families/family.py:195\u001b[0m, in \u001b[0;36mFamily.posterior_predictive\u001b[0;34m(self, model, posterior, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coord_name \u001b[38;5;129;01min\u001b[39;00m coord_names:\n\u001b[1;32m    194\u001b[0m     output_coords[coord_name] \u001b[38;5;241m=\u001b[39m output_coords_all[coord_name]\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_coords\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/xarray/core/dataarray.py:422\u001b[0m, in \u001b[0;36mDataArray.__init__\u001b[0;34m(self, data, coords, dims, name, attrs, indexes, fastpath)\u001b[0m\n\u001b[1;32m    420\u001b[0m data \u001b[38;5;241m=\u001b[39m _check_data_shape(data, coords, dims)\n\u001b[1;32m    421\u001b[0m data \u001b[38;5;241m=\u001b[39m as_compatible_data(data)\n\u001b[0;32m--> 422\u001b[0m coords, dims \u001b[38;5;241m=\u001b[39m \u001b[43m_infer_coords_and_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m variable \u001b[38;5;241m=\u001b[39m Variable(dims, data, attrs, fastpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    424\u001b[0m indexes, coords \u001b[38;5;241m=\u001b[39m _create_indexes_from_coords(coords)\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/xarray/core/dataarray.py:160\u001b[0m, in \u001b[0;36m_infer_coords_and_dims\u001b[0;34m(shape, coords, dims)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m new_coords\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dims \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m v\u001b[38;5;241m.\u001b[39mdims):\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but these \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare not a subset of the DataArray \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(v\u001b[38;5;241m.\u001b[39mdims, v\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m!=\u001b[39m sizes[d]:\n",
      "\u001b[0;31mValueError\u001b[0m: coordinate chain has dimensions ('chain',), but these are not a subset of the DataArray dimensions ('dim_0', 'dim_1', 'dim_2', 'dim_3')"
     ]
    }
   ],
   "source": [
    "# posterior predictive sampling\n",
    "\n",
    "bambi_model.predict(sample, data=new_data, inplace=False, kind=\"pps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c8b7c6d-a073-41d5-9ba6-086d47bda9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the model family to be multivariate\n",
    "\n",
    "setattr(bambi_model.family, \"KIND\", \"Multivariate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66819d5-3db8-48be-bc07-c86e310e30c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'c(rt, response)_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/xarray/core/dataset.py:1382\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1382\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c(rt, response)_dim'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Different Error\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbambi_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/models.py:800\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, idata, kind, data, inplace, include_group_specific)\u001b[0m\n\u001b[1;32m    797\u001b[0m required_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior\u001b[39m\u001b[38;5;124m\"\u001b[39m: idata\u001b[38;5;241m.\u001b[39mposterior}\n\u001b[1;32m    798\u001b[0m optional_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data}\n\u001b[0;32m--> 800\u001b[0m pps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfamily\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposterior_predictive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequired_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptional_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m pps \u001b[38;5;241m=\u001b[39m pps\u001b[38;5;241m.\u001b[39mto_dataset(name\u001b[38;5;241m=\u001b[39mresponse_aliased_name)\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposterior_predictive\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m idata:\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/families/family.py:194\u001b[0m, in \u001b[0;36mFamily.posterior_predictive\u001b[0;34m(self, model, posterior, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m output_coords \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coord_name \u001b[38;5;129;01min\u001b[39;00m coord_names:\n\u001b[0;32m--> 194\u001b[0m     output_coords[coord_name] \u001b[38;5;241m=\u001b[39m \u001b[43moutput_coords_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoord_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xr\u001b[38;5;241m.\u001b[39mDataArray(output_array, coords\u001b[38;5;241m=\u001b[39moutput_coords)\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/xarray/core/coordinates.py:290\u001b[0m, in \u001b[0;36mDatasetCoordinates.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mdata_vars:\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m--> 290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/xarray/core/dataset.py:1473\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkey)\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mhashable(key):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_dataarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39miterable_of_hashable(key):\n\u001b[1;32m   1475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copy_listed(key)\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/xarray/core/dataset.py:1384\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables[name]\n\u001b[1;32m   1383\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 1384\u001b[0m     _, name, variable \u001b[38;5;241m=\u001b[39m \u001b[43m_get_virtual_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1386\u001b[0m needed_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(variable\u001b[38;5;241m.\u001b[39mdims)\n\u001b[1;32m   1388\u001b[0m coords: \u001b[38;5;28mdict\u001b[39m[Hashable, Variable] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/xarray/core/dataset.py:196\u001b[0m, in \u001b[0;36m_get_virtual_variable\u001b[0;34m(variables, key, dim_sizes)\u001b[0m\n\u001b[1;32m    194\u001b[0m split_key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(split_key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    198\u001b[0m ref_name, var_name \u001b[38;5;241m=\u001b[39m split_key\n\u001b[1;32m    199\u001b[0m ref_var \u001b[38;5;241m=\u001b[39m variables[ref_name]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'c(rt, response)_dim'"
     ]
    }
   ],
   "source": [
    "# Different Error\n",
    "\n",
    "bambi_model.predict(sample, data=new_data, inplace=False, kind=\"pps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9310fbec-3433-4e56-bda1-bc475366dc06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multivariate_family = bmb.families.multivariate.MultivariateFamily(\n",
    "    \"WFPT_Family\", likelihood=likelihood, link=links\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f915a98-31e9-43dc-80e7-8c75beb7c729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bambi_model_multi = bmb.Model(\n",
    "    \"c(rt, response) ~ 1 + x + y\",\n",
    "    data=dataset_reg_v,\n",
    "    family=multivariate_family,\n",
    "    priors=priors,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "132aaed1-1f66-48f0-aba2-e2a80246e674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbambi_model_multi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/models.py:314\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, draws, tune, discard_tuned_samples, omit_offsets, include_mean, inference_method, init, n_init, chains, cores, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m         inference_method \u001b[38;5;241m=\u001b[39m method\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# Tell user which event is being modeled\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfamily, univariate\u001b[38;5;241m.\u001b[39mBernoulli):\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/models.py:350\u001b[0m, in \u001b[0;36mModel.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set up the model for sampling/fitting.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \n\u001b[1;32m    343\u001b[0m \u001b[38;5;124;03mCreates an instance of the underlying PyMC model and adds all the necessary terms to it.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;241m=\u001b[39m PyMCModel()\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/backend/pymc.py:70\u001b[0m, in \u001b[0;36mPyMCModel.build\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, component \u001b[38;5;129;01min\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mdistributional_components\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents[name] \u001b[38;5;241m=\u001b[39m DistributionalComponent(component)\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_response(spec)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_potentials(spec)\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/backend/model_components.py:58\u001b[0m, in \u001b[0;36mDistributionalComponent.build\u001b[0;34m(self, pymc_backend, bmb_model)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_response_coords(pymc_backend, bmb_model)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pymc_backend\u001b[38;5;241m.\u001b[39mmodel:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_intercept\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmb_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_offsets()\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_common_terms(pymc_backend, bmb_model)\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/backend/model_components.py:66\u001b[0m, in \u001b[0;36mDistributionalComponent.build_intercept\u001b[0;34m(self, bmb_model)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_intercept\u001b[39m(\u001b[38;5;28mself\u001b[39m, bmb_model):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_intercept:\n\u001b[0;32m---> 66\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mInterceptTerm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomponent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_term\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbmb_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/bambi/backend/terms.py:183\u001b[0m, in \u001b[0;36mInterceptTerm.build\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mfamily, (MultivariateFamily, Categorical)):\n\u001b[1;32m    182\u001b[0m     dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(spec\u001b[38;5;241m.\u001b[39mresponse_component\u001b[38;5;241m.\u001b[39mresponse_term\u001b[38;5;241m.\u001b[39mcoords)\n\u001b[0;32m--> 183\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     dist \u001b[38;5;241m=\u001b[39m dist(label, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterm\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/HSSM/.venv/lib/python3.9/site-packages/pytensor/tensor/var.py:501\u001b[0m, in \u001b[0;36m_tensor_py_operators.__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# Check if the number of dimensions isn't too large.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m index_dim_count:\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo many indices for array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# Convert an Ellipsis if provided into an appropriate number of\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# slice(None).\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ellipses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "bambi_model_multi.fit(cores=1, chains=2, draws=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e765200-8144-4c57-9e3b-41c2bd67e3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Observations: 1000\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v ~ 1 + x + y\n",
       "\tLink: identity\n",
       "\tbounds: (-3.0, 3.0)\n",
       "\tIntercept ~ Uniform(lower: 0.0, upper: 0.5)\n",
       "\tx ~ Uniform(lower: 0.0, upper: 1.0)\n",
       "\ty ~ Uniform(lower: 0.0, upper: 1.0)\n",
       "a ~ Uniform(lower: 0.30000001192092896, upper: 2.5)\tbounds: (0.3, 2.5)\n",
       "z ~ Uniform(lower: 0.10000000149011612, upper: 0.8999999761581421)\tbounds: (0.1, 0.9)\n",
       "t ~ Uniform(lower: 0.0, upper: 2.0)\tbounds: (0.0, 2.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reg_v = hssm.HSSM(\n",
    "    data=dataset_reg_v,\n",
    "    include=[\n",
    "        {\n",
    "            \"name\": \"v\",\n",
    "            \"prior\": {\n",
    "                \"Intercept\": {\"name\": \"Uniform\", \"lower\": 0.0, \"upper\": 0.5},\n",
    "                \"x\": {\"name\": \"Uniform\", \"lower\": 0.0, \"upper\": 1.0},\n",
    "                \"y\": {\"name\": \"Uniform\", \"lower\": 0.0, \"upper\": 1.0},\n",
    "            },\n",
    "            \"formula\": \"v ~ 1 + x + y\",\n",
    "            \"link\": \"identity\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "model_reg_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa1d50-8332-4a70-8064-3c84d927163c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_reg_v = model_reg_v.sample(cores=2, chains=2, draws=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9865482d-e157-487d-8ca9-0b97855d980f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_reg_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7401cc3-1cf9-4c21-b07c-bd0bee7f99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(model_reg_v.traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df108638-4cf4-4195-9ce5-d6fecb8fa412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looks like parameter recovery was successful\n",
    "az.summary(model_reg_v.traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96535980-7a92-4af9-bb50-2128be08e83b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "setattr(model_reg_v.model.family, \"KIND\", \"Multivariate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb58eb-5722-4652-be4e-f10f44c036d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "delattr(model_reg_v.model.family, \"KIND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d996c-19a9-401b-9cc5-778d6734ea2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posterior = model_reg_v.model.predict(\n",
    "    model_reg_v.traces, data=new_data.iloc[1:10, :], inplace=False, kind=\"pps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e63d11c-fb80-49ba-9cd5-c5a474f21c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from bambi.utils import get_aliased_name\n",
    "import pymc as pm\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c98e0b-0d56-4208-ba8c-397dc52abdb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def posterior_predictive(model, posterior, **kwargs):\n",
    "    \"\"\"Get draws from the posterior predictive distribution\n",
    "\n",
    "    This function works for almost all the families. It grabs the draws for the parameters\n",
    "    needed in the response distribution, and then gets samples from the posterior predictive\n",
    "    distribution using `pm.draw()`. It won't work when the response distribution requires\n",
    "    parameters that are not available in `posterior`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : bambi.Model\n",
    "        The model\n",
    "    posterior : xr.Dataset\n",
    "        The xarray dataset that contains the draws for all the parameters in the posterior.\n",
    "        It must contain the parameters that are needed in the distribution of the response, or\n",
    "        the parameters that allow to derive them.\n",
    "    kwargs :\n",
    "        Parameters that are used to get draws but do not appear in the posterior object or\n",
    "        other configuration parameters.\n",
    "        For instance, the 'n' in binomial models and multinomial models.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xr.DataArray\n",
    "        A data array with the draws from the posterior predictive distribution\n",
    "    \"\"\"\n",
    "    response_dist = get_response_dist(model.family)\n",
    "    params = model.family.likelihood.params\n",
    "    response_aliased_name = get_aliased_name(model.response_component.response_term)\n",
    "\n",
    "    kwargs.pop(\"data\", None)  # Remove the 'data' kwarg\n",
    "    dont_reshape = kwargs.pop(\"dont_reshape\", [])\n",
    "    output_dataset_list = []\n",
    "\n",
    "    # In the posterior xr.Dataset we need to consider aliases,\n",
    "    # but we don't use aliases when passing kwargs to the PyMC distribution.\n",
    "    for param in params:\n",
    "        # Extract posterior draws for the parent parameter\n",
    "        if param == model.family.likelihood.parent:\n",
    "            component = model.components[model.response_name]\n",
    "            var_name = response_aliased_name + \"_mean\"\n",
    "            kwargs[param] = posterior[var_name].to_numpy()\n",
    "            output_dataset_list.append(posterior[var_name])\n",
    "        else:\n",
    "            # Extract posterior draws for non-parent parameters\n",
    "            component = model.components[param]\n",
    "            if component.alias:\n",
    "                var_name = component.alias\n",
    "            else:\n",
    "                var_name = f\"{response_aliased_name}_{param}\"\n",
    "\n",
    "            if var_name in posterior:\n",
    "                kwargs[param] = posterior[var_name].to_numpy()\n",
    "                output_dataset_list.append(posterior[var_name])\n",
    "            elif hasattr(component, \"prior\") and isinstance(\n",
    "                component.prior, (int, float)\n",
    "            ):\n",
    "                kwargs[param] = np.asarray(component.prior)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    \"Non-parent parameter not found in posterior.\"\n",
    "                    \"This error shouldn't have happened!\"\n",
    "                )\n",
    "\n",
    "    # Determine the array with largest number of dimensions\n",
    "    ndims_max = max(x.ndim for x in kwargs.values())\n",
    "\n",
    "    # Append a dimension when needed. Required to make `pm.draw()` work.\n",
    "    # However, some distributions like Multinomial, require some parameters to be of a smaller\n",
    "    # dimension than others (n.ndim <= p.ndim - 1) so we don't reshape those.\n",
    "    for key, values in kwargs.items():\n",
    "        if key in dont_reshape:\n",
    "            continue\n",
    "        kwargs[key] = expand_array(values, ndims_max)\n",
    "\n",
    "    if hasattr(model.family, \"transform_kwargs\"):\n",
    "        kwargs = model.family.transform_kwargs(kwargs)\n",
    "\n",
    "    output_array = pm.draw(response_dist.dist(**kwargs))\n",
    "    output_coords_all = xr.merge(output_dataset_list).coords\n",
    "\n",
    "    coord_names = [\"chain\", \"draw\", response_aliased_name + \"_obs\"]\n",
    "    is_multivariate = (\n",
    "        hasattr(model.family, \"KIND\") and model.family.KIND == \"Multivariate\"\n",
    "    )\n",
    "    if is_multivariate:\n",
    "        coord_names.append(response_aliased_name + \"_dim\")\n",
    "\n",
    "    output_coords = {}\n",
    "    for coord_name in coord_names:\n",
    "        output_coords[coord_name] = output_coords_all[coord_name]\n",
    "    return xr.DataArray(output_array, coords=output_coords)\n",
    "\n",
    "\n",
    "def get_response_dist(family):\n",
    "    \"\"\"Get the PyMC distribution for the response\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    family : bambi.Family\n",
    "        The family for which the response distribution is wanted\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pm.Distribution\n",
    "        The response distribution\n",
    "    \"\"\"\n",
    "    mapping = {\"Cumulative\": pm.Categorical, \"StoppingRatio\": pm.Categorical}\n",
    "\n",
    "    if family.likelihood.dist:\n",
    "        dist = family.likelihood.dist\n",
    "    elif family.likelihood.name in mapping:\n",
    "        dist = mapping[family.likelihood.name]\n",
    "    else:\n",
    "        dist = getattr(pm, family.likelihood.name)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def expand_array(x, ndim):\n",
    "    \"\"\"Add dimensions to an array to match the number of desired dimensions\n",
    "\n",
    "    If x.ndim < ndim, it adds ndim - x.ndim dimensions after the last axis. If not, it is left\n",
    "    untouched.\n",
    "\n",
    "    For example, if we have a normal regression model with n = 1000, chains = 2, and draws = 500\n",
    "    the shape of the draws of mu will be (2, 500, 1000) but the shape of the draws of sigma will be\n",
    "    (2, 500). This function makes sure the shape of the draws of sigma is (2, 500, 1) which is\n",
    "    comaptible with (2, 500, 1000).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        The array\n",
    "    ndim : int\n",
    "        The number of desired dimensions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The array with the expanded dimensions\n",
    "    \"\"\"\n",
    "    if x.ndim == ndim:\n",
    "        return x\n",
    "    dims_to_expand = tuple(range(ndim - 1, x.ndim - 1, -1))\n",
    "    return np.expand_dims(x, dims_to_expand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771275a-c44b-40e5-986c-e8cafd91e445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model, idata, kind=\"mean\", data=None, inplace=True, include_group_specific=True\n",
    "):\n",
    "    \"\"\"Predict method for Bambi models\n",
    "\n",
    "    Obtains in-sample and out-of-sample predictions from a fitted Bambi model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    idata : InferenceData\n",
    "        The ``InferenceData`` instance returned by ``.fit()``.\n",
    "    kind : str\n",
    "        Indicates the type of prediction required. Can be ``\"mean\"`` or ``\"pps\"``. The\n",
    "        first returns draws from the posterior distribution of the mean, while the latter\n",
    "        returns the draws from the posterior predictive distribution\n",
    "        (i.e. the posterior probability distribution for a new observation).\n",
    "        Defaults to ``\"mean\"``.\n",
    "    data : pandas.DataFrame or None\n",
    "        An optional data frame with values for the predictors that are used to obtain\n",
    "        out-of-sample predictions. If omitted, the original dataset is used.\n",
    "    include_group_specific : bool\n",
    "        If ``True`` make predictions including the group specific effects. Otherwise,\n",
    "        predictions are made with common effects only (i.e. group specific are set\n",
    "        to zero).\n",
    "    inplace : bool\n",
    "        If ``True`` it will modify ``idata`` in-place. Otherwise, it will return a copy of\n",
    "        ``idata`` with the predictions added. If ``kind=\"mean\"``, a new variable ending in\n",
    "        ``\"_mean\"`` is added to the ``posterior`` group. If ``kind=\"pps\"``, it appends a\n",
    "        ``posterior_predictive`` group to ``idata``. If any of these already exist, it will be\n",
    "        overwritten.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    InferenceData or None\n",
    "    \"\"\"\n",
    "    if kind not in (\"mean\", \"pps\"):\n",
    "        raise ValueError(\"'kind' must be one of 'mean' or 'pps'\")\n",
    "\n",
    "    if not inplace:\n",
    "        idata = deepcopy(idata)\n",
    "\n",
    "    response_aliased_name = get_aliased_name(model.response_component.response_term)\n",
    "\n",
    "    # ALWAYS predict the mean response\n",
    "    means_dict = {}\n",
    "    # To store the HSGP contributions that are also added to the posterior dataset\n",
    "    hsgp_dict = {}\n",
    "    response_dim = response_aliased_name + \"_obs\"\n",
    "    for name, component in model.distributional_components.items():\n",
    "        if name == model.response_name:\n",
    "            var_name = response_aliased_name + \"_mean\"\n",
    "        else:\n",
    "            if component.alias:\n",
    "                var_name = component.alias\n",
    "            else:\n",
    "                var_name = f\"{response_aliased_name}_{name}\"\n",
    "\n",
    "        means_dict[var_name] = component.predict(\n",
    "            idata, data, include_group_specific, hsgp_dict\n",
    "        )\n",
    "\n",
    "        # Drop var/dim if already present. Needed for out-of-sample predictions.\n",
    "        if var_name in idata.posterior.data_vars:\n",
    "            idata.posterior = idata.posterior.drop_vars(var_name)\n",
    "\n",
    "    if response_dim in idata.posterior.dims:\n",
    "        idata.posterior = idata.posterior.drop_dims(response_dim)\n",
    "\n",
    "    # Use the first DataArray to get the number of observations\n",
    "    obs_n = len(list(means_dict.values())[0].coords.get(response_dim))\n",
    "    idata.posterior = idata.posterior.assign_coords({response_dim: list(range(obs_n))})\n",
    "\n",
    "    for name, value in means_dict.items():\n",
    "        idata.posterior[name] = value\n",
    "\n",
    "    # Add HSGP contributions to the posterior dataset\n",
    "    for component in model.distributional_components.values():\n",
    "        for name, hsgp_contribution in hsgp_dict.items():\n",
    "            term = component.hsgp_terms.get(name, None)\n",
    "            if term is None:\n",
    "                continue\n",
    "            term_aliased_name = get_aliased_name(term)\n",
    "            idata.posterior[term_aliased_name] = hsgp_contribution.transpose(\n",
    "                \"chain\", \"draw\", ...\n",
    "            )\n",
    "\n",
    "    # Only if requested predict the predictive distribution\n",
    "    if kind == \"pps\":\n",
    "        required_kwargs = {\"model\": model, \"posterior\": idata.posterior}\n",
    "        optional_kwargs = {\"data\": data}\n",
    "\n",
    "        pps = posterior_predictive(**required_kwargs, **optional_kwargs)\n",
    "        pps = pps.to_dataset(name=response_aliased_name)\n",
    "\n",
    "        if \"posterior_predictive\" in idata:\n",
    "            del idata.posterior_predictive\n",
    "        idata.add_groups({\"posterior_predictive\": pps})\n",
    "        idata.posterior_predictive = idata.posterior_predictive.assign_attrs(\n",
    "            modeling_interface=\"bambi\", modeling_interface_version=__version__\n",
    "        )\n",
    "\n",
    "    if inplace:\n",
    "        return None\n",
    "    else:\n",
    "        return idata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da2e4f-e6fe-4b8c-b51a-8bafd6d7a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\n",
    "    model_reg_v.model,\n",
    "    model_reg_v.traces,\n",
    "    data=new_data.iloc[1:10, :],\n",
    "    inplace=False,\n",
    "    kind=\"pps\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe26e0ab-25ef-4abd-869f-a57509c21a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_function(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a1016-e0ec-4533-a0bd-03ea135dc10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulator always expects a list or matrix\n",
    "\n",
    "# preprocessing in simulator wrapper\n",
    "# take care of special cases --> concatenate into matrix\n",
    "\n",
    "# postprocessing in ...\n",
    "# (chains, trial_output_dim, n_mcmc_samples, n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0044e6-6660-47ec-a97e-4e5a1af4ea56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Logic of output\n",
    "\n",
    "# Definition single sample from posterior predictive (n_samples)\n",
    "\n",
    "# where do the parameters come from --> Uniform sample from the trace!\n",
    "\n",
    "# (n_chains, )\n",
    "# a single posterior predictive sample has the same dimension as our data\n",
    "# and is a simulated version of our dataset when fixing parameters of our model\n",
    "# according to a single uniform draw from our posterior (that is already collected from the .sample() call)\n",
    "\n",
    "#\n",
    "\n",
    "# n samples form posterior predictive is NOT NECESSARILY == n_mcmc samples (which live in parameter space)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
